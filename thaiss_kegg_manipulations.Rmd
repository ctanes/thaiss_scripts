---
title: "kegg_manipulations"
author: "PennCHOP Microbiome Program"
date: \today
output: pdf_document
---


```{r setup, echo=FALSE}
knitr::opts_chunk$set(
  tidy=FALSE,
  cache=FALSE,
  echo=FALSE,
  warning=FALSE,
  message=FALSE,
  dpi=100,
  fig.width=15,
  fig.height=10,
  fig.align = "center"
  )
```

```{r}
library(dplyr)
library(tidyr)
library(broom)
library(ggplot2)
library(ggbeeswarm)
```

```{r}
## define constants
data_dir <- "/Users/tanesc/Documents/thaiss/lila_data"

metadata_fp <- file.path(data_dir, "export_files", "s.txt") ## This is a tab seperated file that contins the metadata for each sample. Each sample is represented by a row and the columns are the additional information you can reference in your code while you are doing the analysis. It is assumed in the code that the Sample names as annotated with the column SampleID. This also coincides with the file name of the output files based on Sunbeam rules.

kegg_info_dir <- file.path(data_dir, "../kegg_links")

preprocess_fp <- file.path(data_dir, "export_files", "preprocess_summary.tsv")
```

```{r}
read_kegg_results <- function(base_dir, s_seq) {
  data_frame(FileName = list.files(
    base_dir, pattern="*_1.txt")) %>%
    group_by(FileName) %>%
    do(read.delim(file.path(base_dir, .$FileName), stringsAsFactors = F)) %>%
    ungroup() %>%
    mutate(SampleID = sub("_1.txt", "", FileName, perl=T)) %>%
    select(-FileName) %>%
    
    group_by(SampleID, geneID) %>%
    summarize(count = sum(count)) %>%
    ungroup() %>%
    
    right_join(select(s_seq, SampleID), by="SampleID") %>%
    
    complete(SampleID, geneID, fill = list(count=0)) %>%
    filter(!is.na(geneID)) %>%
    
    mutate(database = basename(base_dir))
  
}

```

## Read in the data

```{r}
preprocess <- read.delim(preprocess_fp) %>%
  mutate(Samples = sub(".json", "", Samples)) %>%
  rename(SampleID = Samples) %>%
  select(SampleID, nonhost)

s <- read.delim(metadata_fp, sep=" ") %>%
  mutate(experiment = ifelse(grepl("^Ctrl|Gly", SampleID), "exp1", "exp2")) %>%
  mutate(study_group = ifelse(grepl("ctrl", SampleID, ignore.case = T), "Control", "exp")) %>%
  left_join(preprocess, by="SampleID")

```

This contains all the ortholog counts for all the samples.

```{r}
## read in the txt files that contain the counts to KEGG orthologs

kegg_dir <- file.path(data_dir)
kegg <- read_kegg_results(kegg_dir, s) %>%
  left_join(select(preprocess, SampleID, nonhost), by="SampleID") %>%
  mutate(props = count / nonhost)


## Optional: If you would like to annotate your dataframe with the descriptions of all the KEGG orthologs
## You can download the file from here and save as a txt file: http://rest.kegg.jp/list/ko
## For example you can run "wget http://rest.kegg.jp/list/ko -O list_ko.txt" on bash and it will download

kegg_desc <- read.delim(file.path(kegg_info_dir, "list_ko.txt"), header=F) %>%
  setNames(c("geneID", "KO_description")) %>%
  mutate(geneID = sub("ko:", "", geneID))
kegg <- kegg %>%
  left_join(kegg_desc, by="geneID")

```


## Summarize them into pathways

```{r}
## Now we want to group the orthologs into pathways
## We first download the KO to pathway links from the KEGG API
## You can do that by running "wget http://rest.kegg.jp/link/module/ko -O link_ko_module.txt" on your terminal

## There is a slight consideration before we merge everything with our main database. There is probably not a 1-to-1 mapping between the orthologs and modules.
## Meaning one ortholod can map to multiple modules. And of course there are multiple orthologs in a module
## One way to overcome this is to weight the counts. So if an ortholog is in 5 modules, you divide the number of times you see that ortholog in your sample by 5.
## This is the same as multiplying counts with 1/n where n is the number of modules an ortholog is in.
## We first look into the link_ko_module and calculate these weights
kegg_ko_to_path <- read.delim(file.path(kegg_info_dir, "link_ko_path.txt"), header=F)  %>%
  setNames(c("geneID", "path")) %>%
  mutate(geneID = sub("ko:", "", geneID)) %>%
  filter(grepl("map", path)) %>%
  group_by(geneID) %>%
  mutate(weight = 1/n()) %>%
  ungroup()


## If you would not like to weight your counts, you can just run 
#kegg_ko_to_module <- read.delim(file.path(data_dir, "link_ko_module.txt"), header=F)  %>%
#  setNames(c("geneID", "module")) %>%
#  mutate(geneID = sub("ko:", "", geneID))
# but you have to keep in consideration that you will be counting each read multiple times, so you need to be careful when you are calculating relative abundances.


## Now we merge the kegg results with the module mapping file.

kegg_path <- kegg %>%
  left_join(kegg_ko_to_path, by="geneID") %>%
  filter(!is.na(path)) #%>% #not all are assigned to a module. This removes them
  #mutate(props = props * weight)  # we are weighing each count by how manu modules an ortholog is in
  

## Optional: If you would like to annotate your dataframe with the descriptions of all the KEGG orthologs
## You can download the file from here and save as a txt file: http://rest.kegg.jp/list/module
## For example you can run "wget http://rest.kegg.jp/list/module -O list_module.txt" on bash and it will download

path_desc <- read.delim(file.path(kegg_info_dir, "list_path.txt"), header=F) %>%
  setNames(c("path", "pathway_description"))
kegg_path <- kegg_path %>%
  left_join(path_desc, by="path")
write.table(kegg_path, file=file.path(data_dir, "export_files", "kegg_path.txt"), sep='\t', quote=F, row.names=F)


## To calculate the total abundance of a module etc you group by the module for each SampleID and then you sum up the proportions
kegg_path_summed <- kegg_path %>%
  group_by(SampleID, path, pathway_description) %>%
  summarize(path_props = sum(props))
write.table(kegg_path_summed, file=file.path(data_dir, "export_files", "kegg_summed_path.txt"), sep='\t', quote=F, row.names=F)

```



Comparing control to experimental group for each experiment

```{r}
summaries_df <- kegg_path_summed %>%
  left_join(s, by="SampleID") %>%
  
  rename(props = path_props) %>%
  mutate(props_original = props) %>%
  mutate(props = props + 1e-8) %>%
  mutate(props_logit = log(props/(1-props))) %>%
  
  group_by(experiment, path, pathway_description) %>%
  do(tidy(lm(props_logit ~ study_group, data=.))) %>%
  ungroup() %>%
  
  filter(!grepl("Intercept", term)) %>%
  mutate(term = sub("study_group", "Ctrl - ", term)) %>%
  
  group_by(experiment) %>%
  mutate(fdr = p.adjust(p.value, method="BH")) %>%
  ungroup()

write.table(summaries_df, file=file.path(data_dir, "export_files", "lm_results_per_experiment.txt"), sep='\t', quote=F, row.names=F)

```



```{r}
pathway_of_interest <- summaries_df %>%
  filter(fdr < 0.1) %>%
  filter(experiment == "exp1") %>%
  pull(path) %>%
  as.character() %>%
  unique()

kegg_path_summed %>%
  left_join(s, by="SampleID") %>%
  filter(experiment == "exp1") %>%
  filter(path %in% pathway_of_interest) %>%
  ggplot(aes(x=study_group, y=path_props)) +
    geom_boxplot(outlier.alpha=0) +
    geom_quasirandom() +
    theme_bw() +
    facet_wrap(~pathway_description) +
    labs()

```


```{r fig.height=10, fig.width=7}
pathway_of_interest <- summaries_df %>%
  filter(fdr < 0.01) %>%
  filter(experiment == "exp2") %>%
  pull(path) %>%
  as.character() %>%
  unique()

kegg_path_summed %>%
  left_join(s, by="SampleID") %>%
  filter(experiment == "exp2") %>%
  filter(path %in% pathway_of_interest) %>%
  mutate(path_props = path_props + 1e-8) %>%
  mutate(pathway_description = gsub(" ", "\n", pathway_description)) %>%
  ggplot(aes(x=study_group, y=path_props)) +
    geom_boxplot(outlier.alpha=0) +
    geom_quasirandom() +
    theme_bw() +
    theme(strip.background = element_blank()) +
    facet_wrap(~pathway_description, scales="free_y") +
    scale_y_log10(labels=scales:::percent) +
    labs()

ggsave("exp2_diff_ab_pathway.pdf", height=20, width=15, useDingbats=F)
```


Comparing experimental groups for each experiment

```{r}
summaries_df <- kegg_path_summed %>%
  left_join(s, by="SampleID") %>%
  
  rename(props = path_props) %>%
  mutate(props_original = props) %>%
  mutate(props = props + 1e-8) %>%
  mutate(props_logit = log(props/(1-props))) %>%
  
  group_by(study_group, path, pathway_description) %>%
  do(tidy(lm(props_logit ~ experiment, data=.))) %>%
  ungroup() %>%
  
  filter(!grepl("Intercept", term)) %>%
  mutate(term = sub("experiment", "exp1 - ", term)) %>%
  
  group_by(study_group) %>%
  mutate(fdr = p.adjust(p.value, method="BH")) %>%
  ungroup()

write.table(summaries_df, file=file.path(data_dir, "export_files", "lm_results_per_group.txt"), sep='\t', quote=F, row.names=F)

```